from typing import List, Dict
from src.core.data_structures import Task, ExecutionResult, TaskStatus
from src.core.llm_client import Qwen3Client
from src.planning.decomposer import Decomposer
from src.planning.refiner import Refiner
from src.planning.scheduler import Scheduler
from src.execution.mcp_box import DynamicMCPBox
from src.execution.retriever import MCPRetriever
from src.execution.dynamic_dqn import DynamicDQNAgent
from src.execution.executor import MCPExecutor
from src.execution.abstraction import RawMCPPool, MCPAbstractionPipeline
import time

class MultiAgentCoEvolutionSystem:
    """å¤šæ™ºèƒ½ä½“å…±åŒè¿›åŒ–ç³»ç»Ÿ"""
    
    def __init__(self, config: dict):
        self.config = config
        
        # LLMå®¢æˆ·ç«¯
        self.llm = Qwen3Client(
            base_url=config['llm']['base_url'],
            model_name=config['llm']['model_name'],
            temperature=config['llm']['temperature'],
            max_tokens=config['llm']['max_tokens']
        )
        
        # è§„åˆ’å±‚ï¼šå¤šæ™ºèƒ½ä½“
        self.decomposer = Decomposer(self.llm)
        self.refiner = Refiner(self.llm)
        self.scheduler = Scheduler()
        
        # æ‰§è¡Œå±‚ï¼šåŠ¨æ€ç©ºé—´ä¸ç­–ç•¥
        self.mcp_box = DynamicMCPBox()
        self.mcp_box.load()
        
        self.retriever = MCPRetriever(config['retrieval']['model_name'])
        self.dqn_agent = DynamicDQNAgent(config['dqn'], self.retriever)
        self.executor = MCPExecutor(self.llm)
        
        # å­¦ä¹ å±‚ï¼šMCPæŠ½è±¡
        self.raw_mcp_pool = RawMCPPool()
        self.abstraction_pipeline = MCPAbstractionPipeline(
            self.llm,
            config['system']['success_rate_threshold']
        )
        
        # ç»Ÿè®¡
        self.query_count = 0
        self.total_rewards = []
    
    def process_query(self, query: str) -> Dict:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼ˆå®Œæ•´æµç¨‹ï¼‰
        
        Returns:
            ç»“æœå­—å…¸
        """
        self.query_count += 1
        print(f"\n{'='*60}")
        print(f"æŸ¥è¯¢ #{self.query_count}: {query}")
        print(f"{'='*60}")
        
        start_time = time.time()
        
        # ===== é˜¶æ®µ1: å¤šæ™ºèƒ½ä½“åä½œè§„åˆ’ =====
        print("\n[é˜¶æ®µ1] å¤šæ™ºèƒ½ä½“è§„åˆ’...")
        
        # Decomposeråˆ†è§£
        mcps = self.mcp_box.get_all_mcps()
        planning_result = self.decomposer.decompose(query, mcps)
        
        if not planning_result.is_valid:
            return {"success": False, "error": "åˆ†è§£å¤±è´¥"}
        
        print(f"  âœ“ Decomposer: åˆ†è§£ä¸º {len(planning_result.tasks)} ä¸ªä»»åŠ¡")
        
        # RefineréªŒè¯
        planning_result = self.refiner.validate(query, planning_result, mcps)
        
        if not planning_result.is_valid:
            print(f"  âœ— Refiner: éªŒè¯å¤±è´¥ - {planning_result.feedback}")
            # ç®€åŒ–ç‰ˆï¼šä¸é‡æ–°åˆ†è§£ï¼Œç›´æ¥è¿”å›å¤±è´¥
            return {"success": False, "error": planning_result.feedback}
        
        print(f"  âœ“ Refiner: éªŒè¯é€šè¿‡")
        
        # Schedulerè°ƒåº¦
        planning_result = self.scheduler.schedule(planning_result)
        print(f"  âœ“ Scheduler: ç”Ÿæˆ {len(planning_result.execution_plan)} ä¸ªæ‰¹æ¬¡")
        
        # ===== é˜¶æ®µ2: åŠ¨æ€MCPé€‰æ‹©ä¸æ‰§è¡Œ =====
        print("\n[é˜¶æ®µ2] åŠ¨æ€MCPé€‰æ‹©ä¸æ‰§è¡Œ...")
        
        execution_history = []
        task_results = {}
        episode_reward = 0
        
        for batch_idx, batch in enumerate(planning_result.execution_plan):
            print(f"\n  æ‰¹æ¬¡ {batch_idx + 1}/{len(planning_result.execution_plan)}:")
            
            for task_id in batch:
                task = next(t for t in planning_result.tasks if t.id == task_id)
                
                # æ£€ç´¢å€™é€‰MCP
                candidate_mcps = self.retriever.retrieve(
                    task,
                    mcps,
                    top_k=self.config['retrieval']['top_k']
                )
                
                if not candidate_mcps:
                    print(f"    âœ— {task.id}: æ— å¯ç”¨MCP")
                    continue
                
                # DQNé€‰æ‹©MCP
                state = self.dqn_agent.get_state(task, execution_history)
                selected_mcp = self.dqn_agent.select_action(state, candidate_mcps)
                
                print(f"    â†’ {task.id}: é€‰æ‹© {selected_mcp.name} (Îµ={self.dqn_agent.epsilon:.3f})")
                
                # æ‰§è¡Œä»»åŠ¡
                context = {"previous_results": task_results}
                result = self.executor.execute(task, selected_mcp, context)
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                task.status = TaskStatus.SUCCESS if result.success else TaskStatus.FAILED
                task.selected_mcp = selected_mcp.id
                task.result = result.output
                task.execution_time = result.execution_time
                task.token_count = result.token_count
                
                task_results[task.id] = result.output
                
                # è®¡ç®—å¥–åŠ±
                reward = self._compute_reward(task, selected_mcp, result)
                episode_reward += reward
                
                # å­˜å‚¨ç»éªŒ
                next_state = state  # ç®€åŒ–ç‰ˆ
                self.dqn_agent.store_experience(state, selected_mcp, reward, next_state, False)
                
                # æ›´æ–°MCPç»Ÿè®¡
                self.mcp_box.update_stats(selected_mcp.id, result.success, result.token_count)
                
                # æ·»åŠ åˆ°Raw MCP Pool
                if result.success:
                    self.raw_mcp_pool.add(task, selected_mcp, result)
                
                execution_history.append({
                    "task_id": task.id,
                    "mcp_id": selected_mcp.id,
                    "success": result.success,
                    "reward": reward
                })
                
                print(f"      {'âœ“' if result.success else 'âœ—'} æ‰§è¡Œ{'æˆåŠŸ' if result.success else 'å¤±è´¥'} (å¥–åŠ±: {reward:.1f})")
        
        # ===== é˜¶æ®µ3: ç­–ç•¥å­¦ä¹  =====
        print("\n[é˜¶æ®µ3] ç­–ç•¥å­¦ä¹ ...")
        loss = self.dqn_agent.train_step()
        if loss is not None:
            print(f"  âœ“ DQNè®­ç»ƒ: loss={loss:.4f}")
        
        # ===== é˜¶æ®µ4: MCPæŠ½è±¡ï¼ˆå®šæœŸè§¦å‘ï¼‰ =====
        if self.query_count % self.config['system']['mcp_abstraction_threshold'] == 0:
            print("\n[é˜¶æ®µ4] MCPæŠ½è±¡...")
            self._trigger_mcp_abstraction()
        
        # ç»Ÿè®¡
        total_time = time.time() - start_time
        success_count = sum(1 for t in planning_result.tasks if t.status == TaskStatus.SUCCESS)
        total_tasks = len(planning_result.tasks)
        
        self.total_rewards.append(episode_reward)
        
        print(f"\n{'='*60}")
        print(f"å®Œæˆ: {success_count}/{total_tasks} ä»»åŠ¡æˆåŠŸ")
        print(f"æ€»å¥–åŠ±: {episode_reward:.1f} | è€—æ—¶: {total_time:.2f}s")
        print(f"MCP Box: {len(self.mcp_box.mcps)} ä¸ªMCP")
        print(f"{'='*60}")
        
        return {
            "success": success_count == total_tasks,
            "tasks": [t.to_dict() for t in planning_result.tasks],
            "episode_reward": episode_reward,
            "execution_time": total_time,
            "mcp_box_size": len(self.mcp_box.mcps)
        }
    
    def _compute_reward(self, task: Task, mcp, result: ExecutionResult) -> float:
        """è®¡ç®—å¥–åŠ±"""
        if not result.success:
            return -5.0
        
        reward = 10.0  # åŸºç¡€æˆåŠŸå¥–åŠ±
        
        # æ•ˆç‡å¥–åŠ±ï¼ˆtokenå°‘ = å¥–åŠ±é«˜ï¼‰
        if result.token_count < 200:
            reward += 2.0
        
        # è´¨é‡å¥–åŠ±
        reward += result.quality_score * 3.0
        
        return reward
    
    def _trigger_mcp_abstraction(self):
        """è§¦å‘MCPæŠ½è±¡"""
        clusters = self.raw_mcp_pool.find_similar_clusters(
            threshold=self.config['system']['mcp_abstraction_threshold']
        )
        
        if not clusters:
            print("  â†’ æ²¡æœ‰å‘ç°å¯æŠ½è±¡çš„æ¨¡å¼")
            return
        
        print(f"  â†’ å‘ç° {len(clusters)} ä¸ªå€™é€‰ç°‡")
        
        for cluster in clusters:
            new_mcp = self.abstraction_pipeline.abstract(cluster)
            if new_mcp:
                added = self.mcp_box.add_mcp(new_mcp)
                if added:
                    print(f"  âœ“ æŠ½è±¡å‡ºæ–°MCP: {new_mcp.name}")
    
    def save_checkpoint(self, path: str):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        self.mcp_box.save()
        self.dqn_agent.save(f"{path}/dqn_agent.pth")
        print(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹åˆ° {path}")
    
    def get_statistics(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        mcp_stats = self.mcp_box.get_stats()
        
        return {
            "total_queries": self.query_count,
            "avg_reward": sum(self.total_rewards) / len(self.total_rewards) if self.total_rewards else 0,
            "mcp_box_stats": mcp_stats,
            "dqn_epsilon": self.dqn_agent.epsilon,
            "dqn_training_steps": self.dqn_agent.training_steps
        }